# 构建高效 Agent
=========================

原文地址: <https://www.anthropic.com/engineering/building-effective-agents>

我们与各行各业数十个团队合作，帮助他们构建 LLM Agent。我们发现，最成功的实现往往采用简单、可组合的模式，而不是复杂的框架。

过去一年里，我们与众多团队合作，帮助他们构建大语言模型（LLM）Agent。最成功的团队并没有依赖复杂的框架或专用库，而是采用了简单、可组合的模式。

本文将分享我们与客户合作及自研 Agent 的经验，并为开发者提供构建高效 Agent 的实用建议。

什么是 Agent？
----------------

“Agent”有多种定义。有些客户认为 Agent 是完全自主的系统，可以独立运行较长时间，利用各种工具完成复杂任务。也有客户将 Agent 用于更具规范性的实现，遵循预设的工作流。在 Anthropic，我们将这些统称为**Agentic 系统**，但在架构上区分**工作流**与**Agent**：

* **工作流**：LLM 与工具通过预定义的代码路径进行编排。
* **Agent**：LLM 动态自主地指挥流程和工具使用，掌控任务完成方式。

下文将详细介绍这两类 Agentic 系统。在附录 1（“Agent 实践”）中，我们描述了客户在两个领域使用这些系统获得价值的案例。

何时（以及何时不）使用 Agent
---------------------------------

在用 LLM 构建应用时，我们建议优先选择最简单的方案，只有在确有需要时才增加复杂度。这意味着很多时候无需构建 Agentic 系统。Agentic 系统通常以延迟和成本为代价，换取更好的任务表现，你需要权衡这种取舍。

当需要更高复杂度时，工作流适合可预测、任务明确的场景；而 Agent 更适合需要灵活性和模型驱动决策的大规模场景。但对于许多应用，仅通过检索和上下文优化单次 LLM 调用就足够了。

何时以及如何使用框架
------------------------------

市面上有许多框架可以简化 Agentic 系统的实现，包括：

* LangChain 的 [LangGraph](https://langchain-ai.github.io/langgraph/)；
* Amazon Bedrock 的 [AI Agent 框架](https://aws.amazon.com/bedrock/agents/)；
* [Rivet](https://rivet.ironcladapp.com/)，一个拖拽式 GUI LLM 工作流构建器；
* [Vellum](https://www.vellum.ai/)，另一个用于构建和测试复杂工作流的 GUI 工具。

这些框架简化了调用 LLM、定义和解析工具、串联调用等底层任务，方便快速上手。但它们也可能增加抽象层，掩盖底层的提示和响应，导致调试困难。框架还容易让开发者在本可用简单方案时，误用复杂方案。

我们建议开发者优先直接使用 LLM API：许多模式只需几行代码即可实现。如果确实需要框架，请务必理解底层代码。对底层机制的错误假设是客户常见的失误来源。

可参考我们的 [cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents) 获取示例实现。

构建模块、工作流与 Agent
--------------------------------------

本节将介绍我们在生产环境中常见的 Agentic 系统模式。从基础的增强型 LLM 开始，逐步增加复杂度，涵盖从简单组合工作流到自主 Agent。

### 构建模块：增强型 LLM

Agentic 系统的基础模块是经过增强的 LLM，具备检索、工具和记忆等能力。我们的模型可以主动使用这些能力——生成搜索查询、选择合适工具、决定保留哪些信息。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/d3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png?w=3840&q=75)

增强型 LLM

我们建议关注两点：针对具体场景定制这些能力，以及为 LLM 提供易用、文档完善的接口。实现方式多样，其中一种是通过我们新发布的 [模型上下文协议](https://www.anthropic.com/news/model-context-protocol)，开发者可用简单的[客户端实现](https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients)集成第三方工具生态。

下文假设每次 LLM 调用都可访问这些增强能力。

### 工作流：提示链

提示链将任务分解为一系列步骤，每次 LLM 调用处理上一步的输出。你可以在中间步骤加入程序化检查（如下图中的“gate”），确保流程正常。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png?w=3840&q=75)

提示链工作流

**适用场景：** 任务可被清晰分解为固定子任务时。主要目的是以延迟换取更高准确率，让每次 LLM 调用变得更简单。

**示例：**

* 先生成营销文案，再翻译成其他语言。
* 先写文档大纲，检查大纲是否符合要求，再根据大纲写文档。

### 工作流：路由

路由将输入分类，并分配到专门的后续任务。这样可以分离关注点，构建更专业的提示。否则，优化某类输入可能会影响其他输入的表现。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png?w=3840&q=75)

路由工作流

**适用场景：** 复杂任务有不同类别，分别处理效果更好，且分类可由 LLM 或传统模型准确完成。

**示例：**

* 客服问题分流（一般咨询、退款请求、技术支持）到不同流程、提示和工具。
* 简单/常见问题用小模型（如 Claude 3.5 Haiku），复杂/罕见问题用更强模型（如 Claude 3.5 Sonnet），优化成本和速度。

### 工作流：并行化

LLM 可同时处理任务的不同部分，输出可程序化聚合。并行化有两种主要形式：

* **分段**：任务拆分为独立子任务并行处理。
* **投票**：同一任务多次运行，获得多样输出。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png?w=3840&q=75)

并行化工作流

**适用场景：** 子任务可并行提升速度，或需多角度/多次尝试提高结果置信度。复杂任务涉及多方面时，让每个方面单独调用 LLM 效果更好。

**示例：**

* **分段**：
  * 实现防护措施：一个模型处理用户查询，另一个筛查不当内容。比单次 LLM 调用同时处理效果更佳。
  * 自动化评测：每次 LLM 调用评估模型在某一方面的表现。
* **投票**：
  * 代码安全审查：多种提示分别审查代码，发现问题即标记。
  * 内容合规评估：多种提示分别评估不同方面，或设定投票阈值，平衡误报与漏报。

### 工作流：编排者-工作者

编排者-工作者模式下，中心 LLM 动态拆解任务，分配给工作者 LLM，并综合结果。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png?w=3840&q=75)

编排者-工作者工作流

**适用场景：** 复杂任务，无法预知子任务（如编程时需修改的文件数量和内容取决于具体任务）。与并行化类似，但关键区别在于灵活性——子任务由编排者根据输入动态决定。

**示例：**

* 编程产品，每次需对多个文件做复杂修改。
* 搜索任务，需从多个来源收集和分析信息。

### 工作流：评估者-优化者

评估者-优化者模式下，一个 LLM 生成响应，另一个评估并反馈，循环迭代。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png?w=3840&q=75)

评估者-优化者工作流

**适用场景：** 有明确评估标准，且迭代优化能带来实际提升。适合 LLM 响应能通过人类反馈显著改进，且 LLM 能给出有效反馈。类似人类写作反复修改的过程。

**示例：**

* 文学翻译，初稿可能遗漏细节，评估 LLM 可给出有用批评。
* 复杂搜索任务，需多轮搜索和分析，评估者决定是否继续。

### Agent

随着 LLM 在理解复杂输入、推理规划、可靠工具使用和错误恢复等方面成熟，Agent 正在生产环境中崭露头角。Agent 通常由用户命令或交互对话启动，任务明确后，Agent 独立规划和执行，必要时再与用户沟通。执行过程中，Agent 需在每步获取环境“真实反馈”（如工具调用结果、代码执行），以评估进展。Agent 可在检查点或遇到阻碍时暂停，征求人类反馈。任务通常在完成时终止，也可设定停止条件（如最大迭代次数）以控制流程。

Agent 能处理复杂任务，但实现往往很简单，通常就是 LLM 在循环中根据环境反馈使用工具。因此，工具集及其文档设计至关重要。附录 2（“工具提示工程”）将详细介绍工具开发最佳实践。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png?w=3840&q=75)

自主 Agent

**适用场景：** 适合难以预知步骤数量、无法硬编码流程的开放性问题。LLM 可能需多轮操作，你必须信任其决策能力。Agent 的自主性使其非常适合在可信环境中扩展任务。

Agent 的自主性意味着更高成本和错误风险。建议在沙盒环境充分测试，并设置合适的防护措施。

**示例：**

以下为我们自研实现：

* 解决 [SWE-bench 任务](https://www.anthropic.com/research/swe-bench-sonnet) 的编程 Agent，需根据任务描述修改多个文件；
* 我们的 [“电脑操作”参考实现](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)，Claude 使用电脑完成任务。

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png?w=3840&q=75)

编程 Agent 的高层流程

模式组合与定制
----------------------------------------

这些构建模块并非强制，而是常见模式，开发者可根据实际需求灵活组合。关键在于测量效果并不断迭代。再次强调：只有在确实能提升结果时，才应增加复杂度。

总结
-------

LLM 领域的成功不在于构建最复杂的系统，而在于构建最适合自身需求的系统。先用简单提示，结合全面评测优化，只有在简单方案不足时才引入多步 Agentic 系统。

实现 Agent 时，我们遵循三大原则：

1. 保持 Agent 设计的**简洁性**。
2. 优先**透明性**，明确展示 Agent 的规划步骤。
3. 通过完善的工具**文档和测试**，精心打造 Agent-计算机接口（ACI）。

框架有助于快速入门，但随着进入生产阶段，不妨减少抽象层，回归基础组件。遵循这些原则，你将构建出强大、可靠、易维护且受用户信赖的 Agent。

### 致谢

作者：Erik Schluntz 和 Barry Zhang。本文基于我们在 Anthropic 构建 Agent 的经验，以及客户分享的宝贵见解，谨致谢意。

附录 1：Agent 实践
------------------------------

我们与客户合作发现，AI Agent 在两个领域展现出极大价值，充分体现了上述模式的实用性。这两类应用都需要对话与行动、明确成功标准、反馈循环和有效的人类监督。

### A. 客户支持

客户支持结合了传统聊天机器人界面和工具集成能力。Agent 在此场景下表现优异，原因包括：

* 支持交互流程自然需要外部信息和操作；
* 可集成工具，获取客户数据、订单历史和知识库；
* 可程序化处理退款、工单更新等操作；
* 成功可通过用户定义的结果明确衡量。

多家公司已通过按成功解决计费的模式，证明了 Agent 的有效性。

### B. 编程 Agent

软件开发领域对 LLM 功能需求极大，从代码补全到自主解决问题。Agent 尤其有效，原因包括：

* 代码方案可通过自动化测试验证；
* Agent 可根据测试结果迭代优化；
* 问题空间结构化、定义明确；
* 输出质量可客观衡量。

我们自研的 Agent 已能仅凭 PR 描述解决 [SWE-bench Verified](https://www.anthropic.com/research/swe-bench-sonnet) 基准中的真实 GitHub 问题。自动化测试有助于验证功能，但人工审核仍对确保方案符合系统需求至关重要。

附录 2：工具提示工程
-----------------------------------------

无论构建何种 Agentic 系统，工具都极为重要。[工具](https://www.anthropic.com/news/tool-use-ga)让 Claude 能通过 API 与外部服务交互，需明确结构和定义。当 Claude 响应时，若计划调用工具，会在 API 响应中包含[工具调用块](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-api-response-with-a-tool-use-content-block)。工具定义和规范应像整体提示一样精心设计。下面简述工具提示工程方法。

同一操作常有多种规范方式。例如，文件编辑可用 diff 或重写整个文件。结构化输出可用 markdown 或 JSON。对软件工程而言，这些差异可无损转换，但某些格式对 LLM 更难。例如，写 diff 需提前知道变更行数，写 JSON 需额外转义换行和引号。

我们建议如下：

* 给模型足够 token，“思考”后再输出，避免陷入困境。
* 格式应贴近模型在互联网上常见的自然文本。
* 避免格式“负担”，如需准确统计大量行数或转义代码。

一个经验法则是：人机界面（HCI）需投入大量精力，Agent-计算机接口（ACI）也应如此。具体建议：

* 站在模型角度思考，工具描述和参数是否易懂？如果你需要仔细思考，模型也可能如此。好的工具定义应包含用例、边界、输入格式要求和与其他工具的区别。
* 参数名和描述如何优化，让用法更直观？就像为新手开发者写优秀的 docstring，尤其在工具众多时更重要。
* 测试模型如何使用工具：在我们的 [workbench](https://console.anthropic.com/workbench) 上运行大量示例，观察模型易犯的错误并迭代优化。
* [防错设计（Poka-yoke）](https://en.wikipedia.org/wiki/Poka-yoke)：调整参数，使模型更难犯错。

我们在为 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 构建 Agent 时，工具优化花费的时间甚至超过整体提示。例如，模型在切换目录后，使用相对路径的工具易出错。我们改为强制使用绝对路径，模型使用后表现完美。